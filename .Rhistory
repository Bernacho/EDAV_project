knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(rvest)
library(robotstxt)
library(tidyverse)
url <- "https://fangj.github.io/friends/"
paths_allowed(url)
html <- read_html(url)
episodes_list <- html %>% html_nodes("li")  %>% html_nodes("a")
link <- episodes_list %>% html_attr("href")
long_name <- episodes_list %>% html_text
df <- data.frame(long_name,link) %>%
mutate(numbers = str_extract(long_name,"(\\d+-\\d+)|\\d+") ) %>%
mutate(season=ifelse(str_length(str_match(numbers,"\\d+"))==3, substr(numbers,0,1),substr(numbers,0,2) ) ) %>%
mutate(number=str_replace(str_replace(numbers,season,""), paste("-",season,sep = "")  ,"-") ) %>%
mutate(name = trimws(str_replace(long_name,"(\\d+-\\d+)|\\d+","")) )%>%
mutate(link = paste(url,link,sep="")) %>%
mutate(id=paste(season,":",number))
df <- df[colnames(df)!="numbers"]
View(df)
library(textmineR)
# REmoce this
dialogues <- read_csv("data/friends_dialogues.csv")
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(rvest)
library(robotstxt)
library(tidyverse)
# REmoce this
dialogues <- read_csv("data/friends_dialogues.csv")
setwd("Documents/Master/EDAV/EDAV_project")
# REmoce this
dialogues <- read_csv("data/friends_dialogues.csv")
main_characters <- c("MONICA","RACHEL","PHOEBE","ROSS","CHANDLER","JOEY")
dialogues %>%
filter(character %in% main_characters) %>%
ggplot(aes(fct_infreq(character))) +
geom_bar() +
ggtitle("Main characters lines count") +
labs(x="character",y="lines count")
View(dialogues)
#create DTM
dtm <- CreateDtm(dialogues$line,
doc_names = dialogues$ID,
ngram_window = c(1, 2))
rownames(dialogues)
#create DTM
dtm <- CreateDtm(dialogues$line,
doc_names = rownames(dialogues),
ngram_window = c(1, 2))
# documents
vocabulary <- tf$term[ tf$term_freq > 1 & tf$doc_freq < nrow(dtm) / 2 ]dtm = dtm
#create DTM
dtm <- CreateDtm(dialogues$line,
doc_names = rownames(dialogues),
ngram_window = c(1, 2))
#explore the basic frequency
tf <- TermDocFreq(dtm = dtm)
original_tf <- tf %>% select(term, term_freq,doc_freq)
rownames(original_tf) <- 1:nrow(original_tf)# Eliminate words appearing less than 2 times or in more than half of the
# documents
vocabulary <- tf$term[ tf$term_freq > 1 & tf$doc_freq < nrow(dtm) / 2 ]dtm = dtm
View(dtm)
View(tf)
#create DTM
dtm <- CreateDtm(dialogues$line,
doc_names = rownames(dialogues),
ngram_window = c(1, 2))
#explore the basic frequency
tf <- TermDocFreq(dtm = dtm)
original_tf <- tf %>% select(term, term_freq,doc_freq)
rownames(original_tf) <- 1:nrow(original_tf)
# Eliminate words appearing less than 2 times or in more than half of the documents
vocabulary <- tf$term[ tf$term_freq > 1 & tf$doc_freq < nrow(dtm) / 2 ]dtm = dtm
#create DTM
dtm <- CreateDtm(dialogues$line,
doc_names = rownames(dialogues),
ngram_window = c(1, 2))
#explore the basic frequency
tf <- TermDocFreq(dtm = dtm)
original_tf <- tf %>% select(term, term_freq,doc_freq)
rownames(original_tf) <- 1:nrow(original_tf)
# Eliminate words appearing less than 2 times or in more than half of the documents
vocabulary <- tf$term[ tf$term_freq > 1 & tf$doc_freq < nrow(dtm) / 2 ]
dtm = dtm
View(tf)
stopwords::stopwords('en')
class(stopwords::stopwords('en'))
append(stopwords::stopwords('en'),main_characters)
#create DTM
dtm <- CreateDtm(dialogues$line,
doc_names = rownames(dialogues),
stopword_vec = append(stopwords::stopwords('en'),main_characters),
ngram_window = c(1, 2))
tolower(main_characters)
append(stopwords::stopwords('en'),tolower(main_characters))
#create DTM
dtm <- CreateDtm(dialogues$line,
doc_names = rownames(dialogues),
stopword_vec = append(stopwords::stopwords('en'),tolower(main_characters)),
ngram_window = c(1, 2))
#explore the basic frequency
tf <- TermDocFreq(dtm = dtm)
original_tf <- tf %>% select(term, term_freq,doc_freq)
rownames(original_tf) <- 1:nrow(original_tf)
# Eliminate words appearing less than 2 times or in more than half of the documents
vocabulary <- tf$term[ tf$term_freq > 1 & tf$doc_freq < nrow(dtm) / 2 ]
dtm = dtm
